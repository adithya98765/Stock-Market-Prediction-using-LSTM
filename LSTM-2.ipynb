{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIukYtQQOh3o"
      },
      "outputs": [],
      "source": [
        "# Install necessary package if not already installed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Function: load_and_preprocess_data\n",
        "def load_and_preprocess_data():\n",
        "    \"\"\"\n",
        "    Load stock price data from KaggleHub and normalize the 'Close' column.\n",
        "\n",
        "    Returns:\n",
        "        scaled_data (np.array): Normalized values of the 'Close' price.\n",
        "        scaler (MinMaxScaler): Fitted scaler object (for inverse transform\n",
        "        later).\n",
        "    \"\"\"\n",
        "    file_path = \"GOOGL.csv\"\n",
        "    df = kagglehub.load_dataset(\n",
        "        KaggleDatasetAdapter.PANDAS,\n",
        "        \"varpit94/google-stock-data\",\n",
        "        file_path\n",
        "    )\n",
        "    data = df[['Close']].values\n",
        "\n",
        "    # Normalize data to the range [0,1]\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "    return scaled_data, scaler\n",
        "\n",
        "# Function: create_time_windows\n",
        "def create_time_windows(data, window_size):\n",
        "    \"\"\"\n",
        "    Convert the time series data into a set of time windows (input sequences)\n",
        "    and corresponding targets.\n",
        "\n",
        "    Parameters:\n",
        "        data (np.array): The scaled time series data.\n",
        "        window_size (int): The number of past time steps to use as input.\n",
        "\n",
        "    Returns:\n",
        "        X (np.array): Input sequences with shape (samples, window_size,\n",
        "         features).\n",
        "        y (np.array): Target values corresponding to each input sequence.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(data)):\n",
        "        X.append(data[i-window_size:i, 0])\n",
        "        y.append(data[i, 0])\n",
        "\n",
        "    # Convert lists to numpy arrays and reshape\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "    return X, y\n",
        "\n",
        "# Function: build_lstm_model\n",
        "def build_lstm_model(input_shape):\n",
        "    \"\"\"\n",
        "    Build and return an LSTM based time series forecasting model.\n",
        "\n",
        "    Hyperparameters explained:\n",
        "    - LSTM units: 50 units to capture temporal patterns.\n",
        "    - Dropout: 20% to prevent overfitting.\n",
        "    - Dense layer: Single neuron for the final prediction.\n",
        "\n",
        "    Parameters:\n",
        "        input_shape (tuple): Shape of the input data (timesteps, features).\n",
        "\n",
        "    Returns:\n",
        "        model (tf.keras.Model): Compiled LSTM forecasting model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=50))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Function: plot_predictions\n",
        "def plot_predictions(test_data, predictions, title=\"Stock Price Prediction\"):\n",
        "    \"\"\"\n",
        "    Plot the actual stock prices vs the predicted stock prices.\n",
        "\n",
        "    Parameters:\n",
        "        test_data (np.array): The actual stock prices.\n",
        "        predictions (np.array): Predicted stock prices.\n",
        "        title (str): Title for the plot.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(test_data, color='blue', label='Actual Stock Price')\n",
        "    plt.plot(predictions, color='red', label='Predicted Stock Price')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Stock Price')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    np.random.seed(42)  # Set random seed for reproducibility\n",
        "\n",
        "    # Load and preprocess the data\n",
        "    scaled_data, scaler = load_and_preprocess_data()\n",
        "\n",
        "    # Create input-output sequences\n",
        "    window_size = 60\n",
        "    X, y = create_time_windows(scaled_data, window_size)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    split_ratio = 0.8\n",
        "    split_index = int(len(X) * split_ratio)\n",
        "    X_train, y_train = X[:split_index], y[:split_index]\n",
        "    X_test, y_test = X[split_index:], y[split_index:]\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = build_lstm_model((X_train.shape[1], 1))\n",
        "\n",
        "    # Define early stopping callback\n",
        "    early_stop = EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1,\n",
        "              callbacks=[early_stop])\n",
        "\n",
        "    # Predict and inverse transform\n",
        "    predictions = model.predict(X_test)\n",
        "    predictions = scaler.inverse_transform(predictions)\n",
        "    actual_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "    # Plot the results\n",
        "    plot_predictions(actual_prices, predictions, title=\"Google Stock Price\n",
        "    Prediction\")"
      ]
    }
  ]
}